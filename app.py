# =====================
# Imports and App Setup
# =====================
import random
import json
from datetime import datetime
import dateutil.parser
from flask import Flask, render_template, request # Import request for user_id from session/cookies later
from flask_socketio import SocketIO
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.pipeline import Pipeline # Import Pipeline
import pickle
import logging
import nltk
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- NLTK Data Downloads (Ensures data is available at startup) ---
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    logging.info("Downloading NLTK 'punkt' tokenizer data...")
    nltk.download('punkt')
try:
    nltk.data.find('corpora/wordnet')
except LookupError:
    logging.info("Downloading NLTK 'wordnet' corpus data...")
    nltk.download('wordnet')
try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    logging.info("Downloading NLTK 'stopwords' corpus data...")
    nltk.download('stopwords')

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your_secret_key_here' # Needed for Flask-SocketIO
socketio = SocketIO(app, async_mode="threading", cors_allowed_origins="*")

# --- Initialize Lemmatizer and Stop Words ---
lemmatizer = WordNetLemmatizer()
# Combine custom ignore words with NLTK's English stopwords for a more robust set
ignore_words_set = set(['?', '!', '.', ',', 'is', 'a', 'the', 'and', 'to', 'in', 'for', 'on', 'of', 'that', 'it', 'you', 'this', 'are', 'with', 'as', 'at', 'by', 'an', 'be', 'not']).union(set(stopwords.words('english')))

# --- Custom Tokenizer for TfidfVectorizer (Consistency with train_model.py) ---
def custom_tokenizer(text):
    """Tokenizes, lemmatizes, and filters stop words from a sentence."""
    word_list = nltk.word_tokenize(text.lower())
    return [lemmatizer.lemmatize(word) for word in word_list if word.isalnum() and word not in ignore_words_set]

# =====================
# Load Trained Model (if available)
# =====================
intent_model = None # This will now be the Pipeline
words = None        # Still loaded for TF-IDF fallback bag-of-words consistency
classes = None      # Still loaded for TF-IDF fallback, though Pipeline has its own classes_ attribute
model_loaded = False

try:
    with open('intent_model.pkl', 'rb') as f:
        intent_model = pickle.load(f)
    # The Pipeline contains the TF-IDF vectorizer and classifier.
    # We can extract the vocabulary from the TF-IDF step of the pipeline if needed for debugging/consistency.
    # For the TF-IDF fallback, we still rely on the separate 'words.pkl' and 'classes.pkl'
    # which are generated by train_model.py for consistency with its bag-of-words approach.
    with open('words.pkl', 'rb') as f:
        words = pickle.load(f)
    with open('classes.pkl', 'rb') as f:
        classes = pickle.load(f)
    model_loaded = True
    logging.info("Trained model (Pipeline) loaded successfully.")
    # If the pipeline has a 'classes_' attribute, it's good to know for direct access
    if hasattr(intent_model, 'classes_'):
        logging.info(f"Model classes: {intent_model.classes_}")

except FileNotFoundError:
    logging.warning("Trained model files (intent_model.pkl, words.pkl, classes.pkl) not found. Falling back to TF-IDF only.")
except Exception as e:
    logging.error(f"Error loading trained model: {e}")

# =====================
# Data Loading & TF-IDF Setup for Fallback
# =====================
def load_intents():
    """Load intents from the intents.json file."""
    try:
        with open('intents.json', 'r', encoding='utf-8') as file:
            intents_data = json.load(file)
        logging.info("Intents loaded successfully from intents.json.")
        return intents_data['intents']
    except FileNotFoundError:
        logging.error("intents.json not found. Please ensure it's in the same directory.")
        return []
    except json.JSONDecodeError as e:
        logging.error(f"Error decoding intents.json: {e}")
        return []

intents = load_intents()
# Corpus for TF-IDF fallback (should be consistent with training)
corpus = [pattern for intent in intents for pattern in intent.get('patterns', [])]
tfidf_vectorizer = TfidfVectorizer(
    tokenizer=custom_tokenizer, # Use the same custom tokenizer as in training
    lowercase=False,            # Set to False because our custom_tokenizer handles lowercasing
    min_df=1,
    ngram_range=(1, 2)
)
if corpus: # Only fit if corpus is not empty
    tfidf_vectorizer.fit(corpus)
    logging.info("TF-IDF vectorizer fitted for fallback.")
else:
    logging.warning("Corpus is empty. TF-IDF vectorizer will not be fitted for fallback.")

# =====================
# Session Management (In-memory, consider persistence for production)
# =====================
session_data = {} # Stores user-specific context

def update_user_context(user_id, key, value):
    """Update a user's context in the session data without overwriting other keys."""
    if user_id not in session_data:
        session_data[user_id] = {}
        logging.debug(f"Created new session for user_id: {user_id}")
    session_data[user_id][key] = value
    logging.debug(f"Updated context for {user_id}: {key}={value}")

def get_user_context(user_id, key, default=None):
    """Get a specific context value for a user."""
    return session_data.get(user_id, {}).get(key, default)

def clear_user_context(user_id, key=None):
    """Clear specific or all context for a user."""
    if user_id in session_data:
        if key:
            session_data[user_id].pop(key, None)
            logging.debug(f"Cleared context key '{key}' for user_id: {user_id}")
        else:
            session_data.pop(user_id, None)
            logging.info(f"Cleared all context for user_id: {user_id}")


# =====================
# Utility Functions
# =====================
def get_time_based_greeting():
    """Returns a greeting based on the current time of day."""
    current_hour = datetime.now().hour
    if current_hour < 12:
        return "Good morning!"
    elif 12 <= current_hour < 18:
        return "Good afternoon!"
    else:
        return "Good evening!"

def extract_time(text):
    """Extracts a time string from text using dateutil.parser."""
    try:
        parsed_time = dateutil.parser.parse(text, fuzzy=True)
        return parsed_time.strftime("%I:%M %p")
    except ValueError:
        logging.warning(f"Could not extract time from text: '{text}'")
        return None

# =====================
# Enhanced Intent Prediction
# =====================
def predict_intent(user_input):
    """
    Predicts the intent of the user input, using a trained model (Pipeline) if available,
    otherwise falling back to TF-IDF cosine similarity.
    """
    if model_loaded and intent_model:
        # The loaded intent_model is a Pipeline that expects raw text input.
        # It handles its own preprocessing (tokenization, lemmatization, stop words) internally
        # using the custom_tokenizer configured during training.
        try:
            pred_proba = intent_model.predict_proba([user_input])[0]
            confidence = max(pred_proba)
            predicted_class_index = pred_proba.argmax()
            # Access classes from the fitted pipeline's internal classifier if available
            # Or rely on the 'classes' loaded from classes.pkl if the pipeline doesn't expose them easily
            predicted_tag = intent_model.classes_[predicted_class_index] if hasattr(intent_model, 'classes_') else classes[predicted_class_index]

            logging.debug(f"Model prediction for '{user_input}': Tag='{predicted_tag}', Confidence={confidence:.2f}")

            if confidence < 0.4: # Low confidence threshold
                logging.info(f"Model confidence ({confidence:.2f}) too low for '{user_input}'. Falling back to TF-IDF.")
                return tfidf_fallback_predict(user_input)
            return predicted_tag
        except Exception as e:
            logging.error(f"Error during model prediction for '{user_input}': {e}. Falling back to TF-IDF.")
            return tfidf_fallback_predict(user_input)
    else:
        # If no model is loaded, always use TF-IDF
        logging.info(f"No trained model loaded. Using TF-IDF for '{user_input}'.")
        return tfidf_fallback_predict(user_input)

def tfidf_fallback_predict(user_input):
    """Performs intent prediction using TF-IDF cosine similarity as a fallback."""
    if not corpus:
        logging.warning("TF-IDF corpus is empty. Cannot predict intent.")
        return None
    if not tfidf_vectorizer:
        logging.warning("TF-IDF vectorizer not initialized. Cannot predict intent.")
        return None

    # Use the same custom_tokenizer for consistency with how corpus was fitted
    input_vec = tfidf_vectorizer.transform([user_input])
    corpus_vecs = tfidf_vectorizer.transform(corpus) # Re-transform corpus for consistency if needed, or use pre-computed if available

    similarities = cosine_similarity(input_vec, corpus_vecs)[0]

    if similarities.max() < 0.3: # Low similarity threshold
        logging.info(f"TF-IDF similarity ({similarities.max():.2f}) too low for '{user_input}'. Returning None.")
        return None

    best_idx = similarities.argmax()
    pattern_count = 0
    for intent in intents:
        for pattern in intent.get('patterns', []):
            if pattern_count == best_idx:
                logging.debug(f"TF-IDF matched '{user_input}' to intent: {intent['tag']} via pattern: '{pattern}'")
                return intent['tag']
            pattern_count += 1
    logging.warning(f"TF-IDF found a match but couldn't map to intent tag for '{user_input}'.")
    return None

# =====================
# Response Handlers
# =====================

def fallback_response(user_input):
    """Return a fallback response based on user input."""
    logging.info(f"Generating fallback response for: {user_input}")
    user_input_lower = user_input.lower()
    if "help" in user_input_lower:
        return "Sure! I can help with study schedules, subjects, or videos. What would you like to know more about?"
    elif "sorry" in user_input_lower:
        return "No worries! Just let me know what you need help with."
    else:
        return ("I'm not sure how to help with that. Could you ask something else, or try 'help'?\n"
                "Or, you can ask me things like: 'quiz me', 'set a reminder', 'motivate me', or 'study schedule'.")

def handle_awaiting_subject_or_time(user_id, user_input):
    """Handles user input when the bot is awaiting a subject or time, outside of specific intent handlers."""
    if get_user_context(user_id, 'awaiting_subject'):
        update_user_context(user_id, 'study_subject', user_input) # Renamed key for clarity
        clear_user_context(user_id, 'awaiting_subject')
        update_user_context(user_id, 'awaiting_time', True) # Move to awaiting time after subject
        logging.info(f"User {user_id} provided subject: {user_input}. Now awaiting time.")
        return f"Okay, you're focusing on {user_input}. What time(s) are you planning to study it?"
    elif get_user_context(user_id, 'awaiting_time'):
        study_subject = get_user_context(user_id, 'study_subject', 'your subject')
        study_times = user_input.strip()
        update_user_context(user_id, 'study_times', study_times)
        clear_user_context(user_id, 'awaiting_time')
        logging.info(f"User {user_id} provided study times for {study_subject}: {study_times}")
        return f"Acknowledged. You plan to study {study_subject} at {study_times}. I will keep this in mind."
    return fallback_response(user_input) # Should not be reached if context is handled correctly

def rich_response(intent_tag):
    """Return a rich response for supported intents."""
    if intent_tag == "study_material":
        return ("Here is some study material for you!\n"
                "- [Watch Video](https://youtube.com)\n"
                "- [Read Article](https://example.com)")
    return "I'm not sure about that."

# =====================
# Intent-Specific Handlers
# =====================

def handle_greeting(user_id, user_input, intent_obj):
    """Handles the 'greeting' intent."""
    greeting = get_time_based_greeting()
    return f"{greeting}. How can I help you today?"

def handle_set_reminder(user_id, user_input, intent_obj):
    """Handles the 'set_reminder' intent."""
    time_str = extract_time(user_input)
    if time_str:
        update_user_context(user_id, 'reminder_time', time_str)
        return f"Understood. I will set a reminder for you at {time_str} IST."
    else:
        return "To set a reminder, please tell me the specific time (e.g., 'Remind me at 8:00 AM')."

def handle_study_schedule(user_id, user_input, intent_obj):
    """Handles the 'study_schedule' intent, initiating multi-turn context if needed."""
    # This handler primarily initiates the multi-turn. Subsequent turns are handled by handle_awaiting_subject_or_time
    update_user_context(user_id, 'awaiting_subject', True)
    return "To create a study schedule, first, what subject are you focusing on?"

def handle_help(user_id, user_input, intent_obj):
    """Handles the 'help' intent."""
    return "I can assist you with reminders, study schedules, jokes, and more. Just let me know what you need!"

def handle_translate(user_id, user_input, intent_obj):
    """Handles the 'translate' intent."""
    return "To translate, please provide the text and the target language."

def handle_clear_history(user_id, user_input, intent_obj):
    """Handles the 'clear_history' intent by clearing user context."""
    clear_user_context(user_id) # Clear all context for the user
    responses = intent_obj.get('responses', ["Your history has been cleared."])
    return random.choice(responses)

def handle_default_response(user_id, user_input, intent_obj):
    """Handles intents that just need a random response from their defined list."""
    responses = intent_obj.get('responses', [])
    return random.choice(responses) if responses else fallback_response(user_input)

# Dispatch table for intent handlers
dispatch_table = {
    "greeting": handle_greeting,
    "set_reminder": handle_set_reminder,
    "study_schedule": handle_study_schedule, # This now initiates the multi-turn
    "help": handle_help,
    "translate": handle_translate,
    "clear_history": handle_clear_history,
    "study_material": lambda uid, ui, io: rich_response("study_material"), # Direct call to rich_response
    # All other intents use the generic handle_default_response
    "joke": handle_default_response,
    "thankyou": handle_default_response,
    "goodbye": handle_default_response,
    "about_bot": handle_default_response,
    "mood_check": handle_default_response,
    "switch_theme": handle_default_response,
    "language_support": handle_default_response,
    "motivation": handle_default_response,
    "fallback": handle_default_response, # Note: fallback_response is used if intent_tag is None
    "quiz_me": handle_default_response,
    "daily_goal": handle_default_response,
    "break_reminder": handle_default_response,
    "quote": handle_default_response,
    "bored": handle_default_response,
    "who_made_you": handle_default_response,
    "study_music": handle_default_response,
    "self_care": handle_default_response,
    "how_to_study_subject": handle_default_response,
}

# =====================
# Main Chatbot Logic
# =====================
def get_response(user_input, user_id):
    """Main function to get a chatbot response based on user input and context."""
    logging.info(f"Processing user input: '{user_input}' for user_id: {user_id}")

    # Check for ongoing multi-turn conversations first, before intent prediction
    if get_user_context(user_id, 'awaiting_subject') or get_user_context(user_id, 'awaiting_time'):
        logging.info(f"User {user_id} is in a contextual state. Calling handle_awaiting_subject_or_time.")
        return handle_awaiting_subject_or_time(user_id, user_input)

    intent_tag = predict_intent(user_input)

    if intent_tag is None:
        logging.info(f"No intent predicted for '{user_input}'. Returning fallback.")
        return fallback_response(user_input)

    intent_obj = next((i for i in intents if i['tag'] == intent_tag), None)

    if not intent_obj:
        logging.warning(f"Predicted intent tag '{intent_tag}' not found in intents.json. Returning fallback.")
        return fallback_response(user_input)

    # Use the dispatch table to call the appropriate handler
    handler = dispatch_table.get(intent_tag)
    if handler:
        logging.info(f"Calling handler for intent: '{intent_tag}'")
        return handler(user_id, user_input, intent_obj)
    else:
        # This case should ideally not be reached if all intents are in dispatch_table
        logging.warning(f"No specific handler found for intent '{intent_tag}'. Using default response.")
        responses = intent_obj.get('responses', [])
        return random.choice(responses) if responses else fallback_response(user_input)

# =====================
# Flask Routes & SocketIO
# =====================
@app.route('/')
def home():
    """Render the main chat UI."""
    # You might want to generate a unique user_id here or use Flask's session
    # For simplicity, we'll use a client-side generated one for now in script.js
    return render_template('index.html')

@socketio.on('message')
def handle_message(data):
    """Handle incoming messages from the frontend via SocketIO."""
    user_input = data.get('message', '').strip()
    # For a real app, you'd manage user_id more robustly (e.g., Flask session, JWT)
    # For this example, we expect user_id to be sent from the client.
    user_id = data.get('user_id', 'anonymous_user')

    logging.info(f"Received from frontend (user_id: {user_id}): {user_input}")

    if not user_input:
        response_message = "Please enter a message."
        socketio.emit('response', {'message': response_message, 'user_id': user_id})
        logging.info(f"Sent empty input warning to {user_id}: {response_message}")
        return

    response = get_response(user_input, user_id)
    socketio.emit('response', {'message': response, 'user_id': user_id})
    logging.info(f"Sent response to {user_id}: {response}")

# =====================
# Main Entry Point
# =====================
def main():
    """Main function to run the Flask application."""
    logging.info("Starting Flask SocketIO application...")
    # Use a stronger secret key in production
    socketio.run(app, port=5000, debug=True, allow_unsafe_werkzeug=True) # debug=True for development

if __name__ == "__main__":
    main()
